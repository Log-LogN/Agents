import sys
import os
from typing import TypedDict, Annotated

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage, AIMessage
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langchain_mcp_adapters.client import MultiServerMCPClient

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))
from shared.config import settings


class AgentState(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
    execution_brief: str
    final_output: str


SYSTEM_PROMPT = SystemMessage(content="""
You are a cybersecurity vulnerability analysis assistant.

Purpose:
- Identify known vulnerabilities (CVEs)
- Provide severity and risk context
- Use tools for accurate CVE data

This system is for defensive security and risk assessment.
Always use tools when the user asks about vulnerabilities.
""")


SUMMARY_PROMPT = SystemMessage(content="""
Summarize the vulnerability findings clearly.
Include:
- CVE IDs
- Severity levels
- Risk explanation
- Recommended action
""")


def get_mcp_config():
    server_script = os.path.abspath(
        os.path.join(os.path.dirname(__file__), "mcp_server/server.py")
    )
    return {
        "vulnerability": {
            "command": sys.executable,
            "args": [server_script],
            "transport": "stdio",
            "env": os.environ,
        }
    }


async def build_graph():
    client = MultiServerMCPClient(get_mcp_config())
    tools = await client.get_tools()

    llm = ChatOpenAI(
        model=settings.OPENAI_MODEL,
        api_key=settings.OPENAI_API_KEY,
        temperature=0,
    )

    llm_tools = llm.bind_tools(tools)

    async def reasoning_node(state: AgentState):
        user_text = state["messages"][-1].content
        return {"execution_brief": f"Vulnerability analysis task: {user_text}"}

    async def agent_node(state: AgentState):
        guidance = SystemMessage(content=state["execution_brief"])
        response = await llm_tools.ainvoke(
            [SYSTEM_PROMPT, guidance] + state["messages"]
        )
        return {"messages": [response]}

    def should_continue(state: AgentState):
        last = state["messages"][-1]
        if getattr(last, "tool_calls", None):
            return "tools"
        return "summarize"

    async def summarize_node(state: AgentState):
        summary = await llm.ainvoke(
            [SUMMARY_PROMPT, SystemMessage(content=state.get("execution_brief", ""))]
            + state["messages"]
        )
        text = summary.content if isinstance(summary.content, str) else str(summary.content)
        return {"messages": [AIMessage(content=text)], "final_output": text}

    graph = StateGraph(AgentState)
    tool_node = ToolNode(tools)

    graph.add_node("reasoning", reasoning_node)
    graph.add_node("agent", agent_node)
    graph.add_node("tools", tool_node)
    graph.add_node("summarize", summarize_node)

    graph.add_edge(START, "reasoning")
    graph.add_edge("reasoning", "agent")
    graph.add_conditional_edges("agent", should_continue, {
        "tools": "tools",
        "summarize": "summarize"
    })
    graph.add_edge("tools", "summarize")
    graph.add_edge("summarize", END)

    return graph.compile(), client

async def run_vulnerability_agent(message: str) -> dict:
    """
    Run the vulnerability agent once.

    Returns:
    {
        "output": str,
        "tool_calls": list
    }
    """
    graph, client = await build_graph()

    try:
        initial_state = {
            "messages": [HumanMessage(content=message)]
        }

        final_state = await graph.ainvoke(initial_state)

        # ── Extract final output ─────────────────────────────
        output = str(final_state.get("final_output", "") or "")

        if not output:
            for msg in reversed(final_state["messages"]):
                if hasattr(msg, "content") and isinstance(msg.content, str):
                    output = msg.content
                    break

        # ── Collect tool call logs ───────────────────────────
        tool_calls = []
        messages = final_state["messages"]

        for i, msg in enumerate(messages):
            if hasattr(msg, "tool_calls") and msg.tool_calls:
                for tc in msg.tool_calls:

                    tool_output = ""

                    # Next message usually contains tool result
                    if i + 1 < len(messages):
                        next_msg = messages[i + 1]
                        if hasattr(next_msg, "content"):
                            tool_output = _extract_tool_output(next_msg.content)

                    tool_calls.append({
                        "tool_name": tc["name"],
                        "tool_input": tc["args"],
                        "tool_output": tool_output,
                    })

        return {
            "output": output,
            "tool_calls": tool_calls
        }

    finally:
        # Cleanup MCP client if available
        aclose = getattr(client, "aclose", None)
        if aclose:
            try:
                await aclose()
            except Exception:
                pass

import time

def _now_iso():
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())


async def run_vulnerability_agent_stream(message: str):
    """
    Stream execution events.
    """
    graph, client = await build_graph()

    yield {
        "event": "agent_started",
        "data": {"message": message},
        "timestamp": _now_iso(),
    }

    try:
        initial_state = {
            "messages": [HumanMessage(content=message)]
        }

        final_state = None

        async for state in graph.astream(initial_state, stream_mode="values"):
            final_state = state

            messages = state.get("messages", [])
            if not messages:
                continue

            last = messages[-1]

            # Tool started
            tool_calls = getattr(last, "tool_calls", None)
            if tool_calls:
                for tc in tool_calls:
                    yield {
                        "event": "tool_call_started",
                        "data": {
                            "tool_name": tc["name"],
                            "tool_input": tc["args"]
                        },
                        "timestamp": _now_iso(),
                    }
                continue

            # Tool finished
            if getattr(last, "type", "") == "tool":
                yield {
                    "event": "tool_call_completed",
                    "data": {
                        "tool_output": str(last.content)[:2000]
                    },
                    "timestamp": _now_iso(),
                }

        # Final output
        output = ""
        if final_state:
            output = str(final_state.get("final_output", "") or "")

        yield {
            "event": "llm_final",
            "data": {"output": output},
            "timestamp": _now_iso(),
        }

    finally:
        aclose = getattr(client, "aclose", None)
        if aclose:
            try:
                await aclose()
            except Exception:
                pass

import json
import ast

def _extract_tool_output(content):
    """
    Extract real JSON/text from MCP content wrapper.
    """
    try:
        # Case 1: Already dict
        if isinstance(content, dict):
            return content

        # Case 2: List wrapper from MCP
        if isinstance(content, list):
            if content and "text" in content[0]:
                text = content[0]["text"]
                try:
                    return json.loads(text)
                except:
                    return text

        # Case 3: String representation of list/dict
        if isinstance(content, str):
            try:
                parsed = ast.literal_eval(content)
                if isinstance(parsed, list) and parsed and "text" in parsed[0]:
                    text = parsed[0]["text"]
                    try:
                        return json.loads(text)
                    except:
                        return text
            except:
                pass

        return content

    except Exception:
        return str(content)